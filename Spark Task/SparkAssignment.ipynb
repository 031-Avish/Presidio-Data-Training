{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo0Umj7VenX7",
        "outputId": "39ea1e57-01d5-4940-89e6-4312c8b2a56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=845d93d617797c6a446a1bf7219c58d0a8cdd560a82232869223b583bc369dd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "JFfT54iVesUi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"AnalyseCovidData\").getOrCreate()\n",
        "file_path = \"/content/complete.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "kSBbSwuCe2as"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUVnvDDrfSyF",
        "outputId": "af5c1c1c-9f40-4537-bcfe-e9ed16f2ab39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Name of State / UT: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Total Confirmed cases: double (nullable = true)\n",
            " |-- Death: string (nullable = true)\n",
            " |-- Cured/Discharged/Migrated: double (nullable = true)\n",
            " |-- New cases: integer (nullable = true)\n",
            " |-- New deaths: integer (nullable = true)\n",
            " |-- New recovered: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNMQJAFGfZIH",
        "outputId": "6ead837f-7bd8-492d-c978-6222304b1b3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "|      Date|Name of State / UT|Latitude|Longitude|Total Confirmed cases|Death|Cured/Discharged/Migrated|New cases|New deaths|New recovered|\n",
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "|2020-01-30|            Kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-01-31|            Kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-01|            Kerala| 10.8505|  76.2711|                  2.0|    0|                      0.0|        1|         0|            0|\n",
            "|2020-02-02|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        1|         0|            0|\n",
            "|2020-02-03|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-04|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-05|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-06|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-07|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-08|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-09|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-10|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-11|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-12|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-13|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-14|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-15|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-16|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-17|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-18|            Kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62R5A96YfbS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **QUESTION 1 : Convert all state names to lowercase.**"
      ],
      "metadata": {
        "id": "jS3bH9wzfdUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "df = df.withColumn(\"Name of State / UT\", lower(col(\"Name of State / UT\")))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjqzbr4dfrcG",
        "outputId": "757d4ed2-6087-4c6a-fe93-6b3eeba8f828"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "|      Date|Name of State / UT|Latitude|Longitude|Total Confirmed cases|Death|Cured/Discharged/Migrated|New cases|New deaths|New recovered|\n",
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "|2020-01-30|            kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-01-31|            kerala| 10.8505|  76.2711|                  1.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-01|            kerala| 10.8505|  76.2711|                  2.0|    0|                      0.0|        1|         0|            0|\n",
            "|2020-02-02|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        1|         0|            0|\n",
            "|2020-02-03|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-04|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-05|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-06|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-07|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-08|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-09|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-10|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-11|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-12|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-13|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-14|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-15|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-16|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-17|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "|2020-02-18|            kerala| 10.8505|  76.2711|                  3.0|    0|                      0.0|        0|         0|            0|\n",
            "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **QUESTION 2 Find the day with the greatest number of COVID cases.**"
      ],
      "metadata": {
        "id": "toLR-nNXgn77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "max_cases_day = df.orderBy(col(\"Total Confirmed cases\").desc()).select(\"Date\").first()[0]\n",
        "print(max_cases_day)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXT4ExOVg2PF",
        "outputId": "3a7d6ec5-9b28-407b-f840-8c6abbf6c7b0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-08-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find the state with the second-largest number of COVID cases.**"
      ],
      "metadata": {
        "id": "pP0M4ehSg1OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"state_cases\")\n",
        "\n",
        "# Use SQL to perform the aggregation\n",
        "state_cases_df = spark.sql(\"\"\"\n",
        "    SELECT `Name of State / UT`, SUM(`Total Confirmed cases`) AS TotalCases\n",
        "    FROM state_cases\n",
        "    GROUP BY `Name of State / UT`\n",
        "    ORDER BY TotalCases DESC\n",
        "\"\"\")\n",
        "\n",
        "Seond_largest = state_cases_df.collect()\n",
        "print(Seond_largest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pc5LCElhvYO",
        "outputId": "8981f111-2a8e-4b57-ebb0-897257a48bcf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----------+\n",
            "|Name of State / UT| TotalCases|\n",
            "+------------------+-----------+\n",
            "|       maharashtra|1.5192247E7|\n",
            "|        tamil nadu|  7847083.0|\n",
            "|             delhi|  5766124.0|\n",
            "|    andhra pradesh|  2742054.0|\n",
            "|         karnataka|  2733901.0|\n",
            "|           gujarat|  2730710.0|\n",
            "|     uttar pradesh|  2462456.0|\n",
            "|         telangana|  1644466.0|\n",
            "|         rajasthan|  1622247.0|\n",
            "|       west bengal|  1602230.0|\n",
            "|    madhya pradesh|  1291485.0|\n",
            "|             bihar|  1277395.0|\n",
            "|           haryana|  1161598.0|\n",
            "|             assam|  1003558.0|\n",
            "|            odisha|   831767.0|\n",
            "| jammu and kashmir|   685423.0|\n",
            "|            kerala|   596758.0|\n",
            "|            punjab|   539968.0|\n",
            "|         jharkhand|   282717.0|\n",
            "|      chhattisgarh|   256589.0|\n",
            "+------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "[Row(Name of State / UT='uttarakhand', TotalCases=231641.0), Row(Name of State / UT='goa', TotalCases=150799.0), Row(Name of State / UT='tripura', TotalCases=141618.0), Row(Name of State / UT='telengana', TotalCases=103292.0), Row(Name of State / UT='manipur', TotalCases=84000.0), Row(Name of State / UT='puducherry', TotalCases=82967.0), Row(Name of State / UT='himachal pradesh', TotalCases=80549.0), Row(Name of State / UT='ladakh', TotalCases=57213.0), Row(Name of State / UT='telangana***', TotalCases=52466.0), Row(Name of State / UT='nagaland', TotalCases=45006.0), Row(Name of State / UT='chandigarh', TotalCases=42812.0), Row(Name of State / UT='arunachal pradesh', TotalCases=32082.0), Row(Name of State / UT='dadra and nagar haveli and daman and diu', TotalCases=26209.0), Row(Name of State / UT='meghalaya', TotalCases=17980.0), Row(Name of State / UT='sikkim', TotalCases=13897.0), Row(Name of State / UT='andaman and nicobar islands', TotalCases=13569.0), Row(Name of State / UT='mizoram', TotalCases=13335.0), Row(Name of State / UT='union territory of ladakh', TotalCases=58.0), Row(Name of State / UT='union territory of jammu and kashmir', TotalCases=26.0), Row(Name of State / UT='union territory of chandigarh', TotalCases=2.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Identify which Union Territory has the least number of deaths.**"
      ],
      "metadata": {
        "id": "9XMy0oWgigT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "least_deaths_ut_df = spark.sql(\"\"\"\n",
        "    SELECT `Name of State / UT`, SUM(Death) AS TotalDeaths\n",
        "    FROM state_cases\n",
        "    WHERE `Name of State / UT` LIKE 'union territory%'\n",
        "    GROUP BY `Name of State / UT`\n",
        "    ORDER BY TotalDeaths ASC\n",
        "\"\"\")\n",
        "\n",
        "least_deaths_ut = least_deaths_ut_df.first()\n",
        "print(least_deaths_ut)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6oQCXaWiAEt",
        "outputId": "51b0aaeb-5b01-4850-bc41-0fbed5c7bae3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(Name of State / UT='union territory of ladakh', TotalDeaths=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find the state with the lowest Death to Total Confirmed cases ratio.**"
      ],
      "metadata": {
        "id": "IysAs1UnkZ70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowest_ratio_df = spark.sql(\"\"\"\n",
        "    SELECT `Name of State / UT`,\n",
        "           SUM(Death) AS TotalDeaths,\n",
        "           SUM(`Total Confirmed cases`) AS TotalConfirmed,\n",
        "           SUM(Death) / SUM(`Total Confirmed cases`) AS DeathToConfirmedRatio\n",
        "    FROM state_cases\n",
        "    GROUP BY `Name of State / UT`\n",
        "    ORDER BY DeathToConfirmedRatio ASC\n",
        "\"\"\")\n",
        "\n",
        "# Get the state with the lowest Death-to-Total Confirmed cases ratio\n",
        "lowest_ratio_df.show()\n",
        "lowest_ratio_state = lowest_ratio_df.first()\n",
        "print(lowest_ratio_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23CP2ltli8Cm",
        "outputId": "03f7721e-1931-4d97-8caa-f2928a0846fc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+--------------+---------------------+\n",
            "|  Name of State / UT|TotalDeaths|TotalConfirmed|DeathToConfirmedRatio|\n",
            "+--------------------+-----------+--------------+---------------------+\n",
            "|union territory o...|        0.0|          58.0|                  0.0|\n",
            "|union territory o...|        0.0|          26.0|                  0.0|\n",
            "|union territory o...|        0.0|           2.0|                  0.0|\n",
            "|             mizoram|        0.0|       13335.0|                  0.0|\n",
            "|             manipur|       43.0|       84000.0| 5.119047619047619E-4|\n",
            "|              sikkim|       10.0|       13897.0| 7.195797654169965E-4|\n",
            "|            nagaland|       60.0|       45006.0| 0.001333155579256...|\n",
            "|dadra and nagar h...|       46.0|       26209.0| 0.001755122286237552|\n",
            "|              ladakh|      127.0|       57213.0| 0.002219775225910...|\n",
            "|               assam|     2318.0|     1003558.0| 0.002309781796368521|\n",
            "|             tripura|      364.0|      141618.0| 0.002570294736544...|\n",
            "|   arunachal pradesh|       92.0|       32082.0| 0.002867651642665669|\n",
            "|              kerala|     2399.0|      596758.0| 0.004020055030682454|\n",
            "|andaman and nicob...|       64.0|       13569.0| 0.004716633502837...|\n",
            "|              odisha|     4138.0|      831767.0| 0.004974950917744993|\n",
            "|        chhattisgarh|     1307.0|      256589.0| 0.005093749147469299|\n",
            "|                 goa|      912.0|      150799.0| 0.006047785462768321|\n",
            "|               bihar|     8487.0|     1277395.0| 0.006643990308401082|\n",
            "|        telangana***|      455.0|       52466.0| 0.008672283002325315|\n",
            "|           jharkhand|     2485.0|      282717.0| 0.008789708436351545|\n",
            "+--------------------+-----------+--------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Row(Name of State / UT='union territory of ladakh', TotalDeaths=0.0, TotalConfirmed=58.0, DeathToConfirmedRatio=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find which month had the most \"newer\" recovered cases**"
      ],
      "metadata": {
        "id": "8dtF0Dh1tdgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import  to_date\n",
        "most_recovered_month_df = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        year(Date) AS Year,\n",
        "        month(Date) AS Month,\n",
        "        SUM(`New recovered`) AS TotalRecovered\n",
        "    FROM state_cases\n",
        "    GROUP BY Year, Month\n",
        "    ORDER BY TotalRecovered DESC\n",
        "\n",
        "\"\"\")\n",
        "most_recovered_month = most_recovered_month_df.collect()[0]\n",
        "\n",
        "month_names = {\n",
        "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\",\n",
        "    5: \"May\", 6: \"June\", 7: \"July\", 8: \"August\",\n",
        "    9: \"September\", 10: \"October\", 11: \"November\", 12: \"December\"\n",
        "}\n",
        "month_name = month_names.get(most_recovered_month['Month'])\n",
        "print(month_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpfijYNusxw9",
        "outputId": "e773ed51-a331-4be3-9311-b13dcd8bc03e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "July\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_YokSz2u5bo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}